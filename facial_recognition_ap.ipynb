{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rayanarocha/facial-recognition-app/blob/main/facial_recognition_ap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bibliotecas principais\n",
        "- A biblioteca `os` é um **sistema operacional** que vai ser utilizado na criação de estrutura de pastas\n",
        "- Numpy é utlizado para manipular **arrays**\n",
        "- Matplotlib para plotar os gráficos"
      ],
      "metadata": {
        "id": "PB5d8djLpGP7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DDf4j9XPvBo"
      },
      "source": [
        "## 1.1 Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ6MqZyXPvBp",
        "outputId": "4f7b4f04-3611-497b-acc5-76597ca1fce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==2.4.1 in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: tensorflow-gpu==2.4.1 in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.3.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.32.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.19.6)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.12)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.9.1)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.4.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.10.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.7.4.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.15.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.38.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.14.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (4.13.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.2.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 opencv-python matplotlib  --use-deprecated=legacy-resolver"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJZmVaeeqcqD",
        "outputId": "347d719c-02ac-4b9b-a56c-41e37073592f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vVVf2hEPvBq"
      },
      "source": [
        "## 1.2 Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YmiPw2EaPvBq"
      },
      "outputs": [],
      "source": [
        "# Import standard dependencies\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### O que são Redes Neurais Siamesas?\n",
        "\n",
        "Redes Neurais Siamesas (RNS) foram introduzidas por Bromley em colaboração, no ano de 1994, onde foram utilizadas para realizara veriﬁcação de assinaturas. A arquitetura de uma RNS, consiste em duas redes neurais que compartilham pesos idênticos e que são ligadas por uma ou mais camadas. Na maioria dos casos, uma RNS executa uma codiﬁcação não linear dos dados de entrada com o objetivo de atingir um espaço semanticamente signiﬁcativo onde padrões relacionados sejam próximos uns dos outros (tais como faces de pessoas, assinaturas,entre outros) e os não relacionados sejam distantes unsdos dos outros (Harandi et al., 2017)."
      ],
      "metadata": {
        "id": "UZKvokXauCMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `from tensorflow.keras.models import Model` importa Modelos e agrupa camadas em um objeto com recursos de treinamento e inferência. Ele recebe a imagem de `input` a retorna **0** se a imagem for diferente e **1** se for igual no `output`\n",
        "\n",
        "- from tensorflow.keras.layers importa as camadas possibilitando a criação de uma camada personalizada"
      ],
      "metadata": {
        "id": "iBata_EaxU6e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WE2IMbpzPvBr"
      },
      "outputs": [],
      "source": [
        "# Import tensorflow dependencies - Functional API\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3wRai6hPvBr"
      },
      "source": [
        "## 1.3 Set GPU Growth"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuração da GPU"
      ],
      "metadata": {
        "id": "gXPRrUlYxF6n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Bvoc6MJ1PvBr"
      },
      "outputs": [],
      "source": [
        "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus: \n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(gpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vutfqPQ5lhh-",
        "outputId": "7c1afa77-a2af-4c94-b663-dc937acd914c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLP9CGMnPvBs"
      },
      "source": [
        "## 1.4 Create Folder Structures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ggnRESVMPvBs"
      },
      "outputs": [],
      "source": [
        "# Setup paths\n",
        "POS_PATH = os.path.join('data', 'positive')\n",
        "NEG_PATH = os.path.join('data', 'negative')\n",
        "ANC_PATH = os.path.join('data', 'anchor')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "POS_PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "c55ewtngndXJ",
        "outputId": "1c9bede5-6922-47af-f4db-68178a562745"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data/positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "y6mZOH8RPvBs"
      },
      "outputs": [],
      "source": [
        "# Make the directories\n",
        "os.makedirs(POS_PATH)\n",
        "os.makedirs(NEG_PATH)\n",
        "os.makedirs(ANC_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuQkdXGXPvBt"
      },
      "source": [
        "# 2. Collect Positives and Anchors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK-lhWhDPvBt"
      },
      "source": [
        "## 2.1 Untar Labelled Faces in the Wild Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zKz0hUxePvBt"
      },
      "outputs": [],
      "source": [
        "# http://vis-www.cs.umass.edu/lfw/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eg0w_E1YPvBu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee82f60e-198e-4eb1-e810-901fe8ede85b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: lfw.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ],
      "source": [
        "# Uncompress Tar GZ Labelled Faces in the Wild Dataset\n",
        "!tar -xf lfw.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XxvSTQuXPvBu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "0b4e87d7-fd4b-4169-e522-f4ab2c735254"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b7ea30580a6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Move LFW Images to the following repository data/negative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lfw'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lfw'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mEX_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lfw'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mNEW_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNEG_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lfw'"
          ]
        }
      ],
      "source": [
        "# Move LFW Images to the following repository data/negative\n",
        "for directory in os.listdir('lfw'):\n",
        "    for file in os.listdir(os.path.join('lfw', directory)):\n",
        "        EX_PATH = os.path.join('lfw', directory, file)\n",
        "        NEW_PATH = os.path.join(NEG_PATH, file)\n",
        "        os.replace(EX_PATH, NEW_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv2g9qzXPvBu"
      },
      "source": [
        "## 2.2 Collect Positive and Anchor Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBQEeacvPvBu"
      },
      "outputs": [],
      "source": [
        "# Import uuid library to generate unique image names\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4nZZVsJPvBv"
      },
      "outputs": [],
      "source": [
        "os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqLCpz3RPvBv"
      },
      "outputs": [],
      "source": [
        "# Establish a connection to the webcam\n",
        "cap = cv2.VideoCapture(4)\n",
        "while cap.isOpened(): \n",
        "    ret, frame = cap.read()\n",
        "   \n",
        "    # Cut down frame to 250x250px\n",
        "    frame = frame[120:120+250,200:200+250, :]\n",
        "    \n",
        "    # Collect anchors \n",
        "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
        "        # Create the unique file path \n",
        "        imgname = os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
        "        # Write out anchor image\n",
        "        cv2.imwrite(imgname, frame)\n",
        "    \n",
        "    # Collect positives\n",
        "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
        "        # Create the unique file path \n",
        "        imgname = os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
        "        # Write out positive image\n",
        "        cv2.imwrite(imgname, frame)\n",
        "    \n",
        "    # Show image back to screen\n",
        "    cv2.imshow('Image Collection', frame)\n",
        "    \n",
        "    # Breaking gracefully\n",
        "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
        "        break\n",
        "        \n",
        "# Release the webcam\n",
        "cap.release()\n",
        "# Close the image show frame\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOj5AnOaPvBv"
      },
      "outputs": [],
      "source": [
        "plt.imshow(frame[120:120+250,200:200+250, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS644c07PvBw"
      },
      "source": [
        "# 2.x NEW - Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oa2xUiZxPvBw"
      },
      "outputs": [],
      "source": [
        "def data_aug(img):\n",
        "    data = []\n",
        "    for i in range(9):\n",
        "        img = tf.image.stateless_random_brightness(img, max_delta=0.02, seed=(1,2))\n",
        "        img = tf.image.stateless_random_contrast(img, lower=0.6, upper=1, seed=(1,3))\n",
        "        # img = tf.image.stateless_random_crop(img, size=(20,20,3), seed=(1,2))\n",
        "        img = tf.image.stateless_random_flip_left_right(img, seed=(np.random.randint(100),np.random.randint(100)))\n",
        "        img = tf.image.stateless_random_jpeg_quality(img, min_jpeg_quality=90, max_jpeg_quality=100, seed=(np.random.randint(100),np.random.randint(100)))\n",
        "        img = tf.image.stateless_random_saturation(img, lower=0.9,upper=1, seed=(np.random.randint(100),np.random.randint(100)))\n",
        "            \n",
        "        data.append(img)\n",
        "    \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RU5-fJTcPvBw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejAiZrm7PvBw"
      },
      "outputs": [],
      "source": [
        "img_path = os.path.join(ANC_PATH, '9F5F3C20-F3C6-41D2-88E6-B3B9BF148C22.jpg')\n",
        "img = cv2.imread(img_path)\n",
        "augmented_images = data_aug(img)\n",
        "\n",
        "for image in augmented_images:\n",
        "    cv2.imwrite(os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1())), image.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "G6mZjYcLPvBx"
      },
      "outputs": [],
      "source": [
        "for file_name in os.listdir(os.path.join(POS_PATH)):\n",
        "    img_path = os.path.join(POS_PATH, file_name)\n",
        "    img = cv2.imread(img_path)\n",
        "    augmented_images = data_aug(img) \n",
        "    \n",
        "    for image in augmented_images:\n",
        "        cv2.imwrite(os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1())), image.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PduBRUIPvBx"
      },
      "source": [
        "# 3. Load and Preprocess Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu0r1megPvBx"
      },
      "source": [
        "## 3.1 Get Image Directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8s9VgmD6PvBx"
      },
      "outputs": [],
      "source": [
        "anchor = tf.data.Dataset.list_files(ANC_PATH+'/*.jpg').take(3000)\n",
        "positive = tf.data.Dataset.list_files(POS_PATH+'/*.jpg').take(3000)\n",
        "negative = tf.data.Dataset.list_files(NEG_PATH+'/*.jpg').take(3000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W5qOQyVPvBx"
      },
      "outputs": [],
      "source": [
        "dir_test = anchor.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57mal-NQPvBy"
      },
      "outputs": [],
      "source": [
        "print(dir_test.next())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxIe-IfDPvBy"
      },
      "source": [
        "## 3.2 Preprocessing - Scale and Resize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLiCnPCAPvBy"
      },
      "outputs": [],
      "source": [
        "def preprocess(file_path):\n",
        "    \n",
        "    # Read in image from file path\n",
        "    byte_img = tf.io.read_file(file_path)\n",
        "    # Load in the image \n",
        "    img = tf.io.decode_jpeg(byte_img)\n",
        "    \n",
        "    # Preprocessing steps - resizing the image to be 100x100x3\n",
        "    img = tf.image.resize(img, (100,100))\n",
        "    # Scale image to be between 0 and 1 \n",
        "    img = img / 255.0\n",
        "\n",
        "    # Return image\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "mWi5Cr8vPvBz"
      },
      "outputs": [],
      "source": [
        "img = preprocess('data/anchor/9F5F3C20-F3C6-41D2-88E6-B3B9BF148C22.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5WFkkXiPvBz"
      },
      "outputs": [],
      "source": [
        "img.numpy().max() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GpVrcP9PvBz"
      },
      "outputs": [],
      "source": [
        "dataset.map(preprocess)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-lG3L1sPvBz"
      },
      "source": [
        "## 3.3 Create Labelled Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IX0bs14jPvB0"
      },
      "outputs": [],
      "source": [
        "# (anchor, positive) => 1,1,1,1,1\n",
        "# (anchor, negative) => 0,0,0,0,0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKuwcP1JPvB0"
      },
      "outputs": [],
      "source": [
        "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
        "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
        "data = positives.concatenate(negatives)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CWYxFxYPvB0"
      },
      "outputs": [],
      "source": [
        "samples = data.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsm1hfTYPvB0"
      },
      "outputs": [],
      "source": [
        "exampple = samples.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "C8jSzOEmPvB1"
      },
      "outputs": [],
      "source": [
        "exampple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQawc1NIPvB1"
      },
      "source": [
        "## 3.4 Build Train and Test Partition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leUhoA7NPvB1"
      },
      "outputs": [],
      "source": [
        "def preprocess_twin(input_img, validation_img, label):\n",
        "    return(preprocess(input_img), preprocess(validation_img), label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRvlYCYjPvB1"
      },
      "outputs": [],
      "source": [
        "res = preprocess_twin(*exampple)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68ZfuDu5PvB1"
      },
      "outputs": [],
      "source": [
        "plt.imshow(res[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PwUtcd9PvB2"
      },
      "outputs": [],
      "source": [
        "res[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWxWwKR8PvB2"
      },
      "outputs": [],
      "source": [
        "# Build dataloader pipeline\n",
        "data = data.map(preprocess_twin)\n",
        "data = data.cache()\n",
        "data = data.shuffle(buffer_size=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eTxF9V8PvB2"
      },
      "outputs": [],
      "source": [
        "# Training partition\n",
        "train_data = data.take(round(len(data)*.7))\n",
        "train_data = train_data.batch(16)\n",
        "train_data = train_data.prefetch(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CA4IwQ7bPvB2"
      },
      "outputs": [],
      "source": [
        "# Testing partition\n",
        "test_data = data.skip(round(len(data)*.7))\n",
        "test_data = test_data.take(round(len(data)*.3))\n",
        "test_data = test_data.batch(16)\n",
        "test_data = test_data.prefetch(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9U4NTxoPvB2"
      },
      "source": [
        "# 4. Model Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc6489pUPvB3"
      },
      "source": [
        "## 4.1 Build Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HFEYTuHPvB3"
      },
      "outputs": [],
      "source": [
        "inp = Input(shape=(100,100,3), name='input_image')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AC6KaLlSPvB3"
      },
      "outputs": [],
      "source": [
        "c1 = Conv2D(64, (10,10), activation='relu')(inp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9ZXox0WPvB3"
      },
      "outputs": [],
      "source": [
        "m1 = MaxPooling2D(64, (2,2), padding='same')(c1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOfw2sq5PvB3"
      },
      "outputs": [],
      "source": [
        "c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
        "m2 = MaxPooling2D(64, (2,2), padding='same')(c2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJu2Vo-WPvB3"
      },
      "outputs": [],
      "source": [
        "c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
        "m3 = MaxPooling2D(64, (2,2), padding='same')(c3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGSp8M5GPvB4"
      },
      "outputs": [],
      "source": [
        "c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
        "f1 = Flatten()(c4)\n",
        "d1 = Dense(4096, activation='sigmoid')(f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_YPrJG7PvB4"
      },
      "outputs": [],
      "source": [
        "mod = Model(inputs=[inp], outputs=[d1], name='embedding')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ku7HDXO0PvB4"
      },
      "outputs": [],
      "source": [
        "mod.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJufOJRlPvB4"
      },
      "outputs": [],
      "source": [
        "def make_embedding(): \n",
        "    inp = Input(shape=(100,100,3), name='input_image')\n",
        "    \n",
        "    # First block\n",
        "    c1 = Conv2D(64, (10,10), activation='relu')(inp)\n",
        "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
        "    \n",
        "    # Second block\n",
        "    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
        "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
        "    \n",
        "    # Third block \n",
        "    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
        "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
        "    \n",
        "    # Final embedding block\n",
        "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
        "    f1 = Flatten()(c4)\n",
        "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
        "    \n",
        "    \n",
        "    return Model(inputs=[inp], outputs=[d1], name='embedding')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LdAthOcPvB4"
      },
      "outputs": [],
      "source": [
        "embedding = make_embedding()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLQPAyXvPvB5"
      },
      "outputs": [],
      "source": [
        "embedding.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhM1pkdpPvB5"
      },
      "source": [
        "## 4.2 Build Distance Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8W5uOEkPvB5"
      },
      "outputs": [],
      "source": [
        "# Siamese L1 Distance class\n",
        "class L1Dist(Layer):\n",
        "    \n",
        "    # Init method - inheritance\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "       \n",
        "    # Magic happens here - similarity calculation\n",
        "    def call(self, input_embedding, validation_embedding):\n",
        "        return tf.math.abs(input_embedding - validation_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVQkCXpdPvB5"
      },
      "outputs": [],
      "source": [
        "l1 = L1Dist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "t_KAg4rTPvB5"
      },
      "outputs": [],
      "source": [
        "l1(anchor_embedding, validation_embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1-NpQuJPvB6"
      },
      "source": [
        "## 4.3 Make Siamese Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FL0xS1EPvB6"
      },
      "outputs": [],
      "source": [
        "input_image = Input(name='input_img', shape=(100,100,3))\n",
        "validation_image = Input(name='validation_img', shape=(100,100,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ak_eTSO_PvB6"
      },
      "outputs": [],
      "source": [
        "inp_embedding = embedding(input_image)\n",
        "val_embedding = embedding(validation_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN5u170fPvB6"
      },
      "outputs": [],
      "source": [
        "siamese_layer = L1Dist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNMIS6sQPvB7"
      },
      "outputs": [],
      "source": [
        "distances = siamese_layer(inp_embedding, val_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17tEnjHWPvB7"
      },
      "outputs": [],
      "source": [
        "classifier = Dense(1, activation='sigmoid')(distances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2g4f8x9PvB7"
      },
      "outputs": [],
      "source": [
        "classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc2yYttvPvB7"
      },
      "outputs": [],
      "source": [
        "siamese_network = Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glLmLqfyPvB7"
      },
      "outputs": [],
      "source": [
        "siamese_network.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4shedQ-PvB7"
      },
      "outputs": [],
      "source": [
        "def make_siamese_model(): \n",
        "    \n",
        "    # Anchor image input in the network\n",
        "    input_image = Input(name='input_img', shape=(100,100,3))\n",
        "    \n",
        "    # Validation image in the network \n",
        "    validation_image = Input(name='validation_img', shape=(100,100,3))\n",
        "    \n",
        "    # Combine siamese distance components\n",
        "    siamese_layer = L1Dist()\n",
        "    siamese_layer._name = 'distance'\n",
        "    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
        "    \n",
        "    # Classification layer \n",
        "    classifier = Dense(1, activation='sigmoid')(distances)\n",
        "    \n",
        "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgy7iVWUPvB8"
      },
      "outputs": [],
      "source": [
        "siamese_model = make_siamese_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "OttEUxLpPvB8"
      },
      "outputs": [],
      "source": [
        "siamese_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyB2O7uFPvB8"
      },
      "source": [
        "# 5. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_0Bv6LCPvB8"
      },
      "source": [
        "## 5.1 Setup Loss and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDhzFnD5PvB8"
      },
      "outputs": [],
      "source": [
        "binary_cross_loss = tf.losses.BinaryCrossentropy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9Siw_yOPvB9"
      },
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.Adam(1e-4) # 0.0001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx7U5qNYPvB9"
      },
      "source": [
        "## 5.2 Establish Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgQtTAbMPvB9"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3KRwjL7PvB9"
      },
      "source": [
        "## 5.3 Build Train Step Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qn9Hx9mIPvB9"
      },
      "outputs": [],
      "source": [
        "test_batch = train_data.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOthV8b1PvB9"
      },
      "outputs": [],
      "source": [
        "batch_1 = test_batch.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xogbI4jzPvB-"
      },
      "outputs": [],
      "source": [
        "X = batch_1[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDBPuP3VPvB-"
      },
      "outputs": [],
      "source": [
        "y = batch_1[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hgoqp2APvB-"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "cdWdWkt4PvB-"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(batch):\n",
        "    \n",
        "    # Record all of our operations \n",
        "    with tf.GradientTape() as tape:     \n",
        "        # Get anchor and positive/negative image\n",
        "        X = batch[:2]\n",
        "        # Get label\n",
        "        y = batch[2]\n",
        "        \n",
        "        # Forward pass\n",
        "        yhat = siamese_model(X, training=True)\n",
        "        # Calculate loss\n",
        "        loss = binary_cross_loss(y, yhat)\n",
        "    print(loss)\n",
        "        \n",
        "    # Calculate gradients\n",
        "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
        "    \n",
        "    # Calculate updated weights and apply to siamese model\n",
        "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
        "        \n",
        "    # Return loss\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE7oYCC4PvB_"
      },
      "source": [
        "## 5.4 Build Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2NHfTBrPvB_"
      },
      "outputs": [],
      "source": [
        "# Import metric calculations\n",
        "from tensorflow.keras.metrics import Precision, Recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEr9jlbDPvB_"
      },
      "outputs": [],
      "source": [
        "def train(data, EPOCHS):\n",
        "    # Loop through epochs\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
        "        progbar = tf.keras.utils.Progbar(len(data))\n",
        "        \n",
        "        # Creating a metric object \n",
        "        r = Recall()\n",
        "        p = Precision()\n",
        "        \n",
        "        # Loop through each batch\n",
        "        for idx, batch in enumerate(data):\n",
        "            # Run train step here\n",
        "            loss = train_step(batch)\n",
        "            yhat = siamese_model.predict(batch[:2])\n",
        "            r.update_state(batch[2], yhat)\n",
        "            p.update_state(batch[2], yhat) \n",
        "            progbar.update(idx+1)\n",
        "        print(loss.numpy(), r.result().numpy(), p.result().numpy())\n",
        "        \n",
        "        # Save checkpoints\n",
        "        if epoch % 10 == 0: \n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hQI_1ARPvB_"
      },
      "source": [
        "## 5.5 Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2bkiUhPPvCA"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "9-L9S98YPvCA"
      },
      "outputs": [],
      "source": [
        "train(train_data, EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "miafFeB5PvCA"
      },
      "source": [
        "# 6. Evaluate Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLYa_iDjPvCA"
      },
      "source": [
        "## 6.1 Import Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJjrfW6UPvCA"
      },
      "outputs": [],
      "source": [
        "# Import metric calculations\n",
        "from tensorflow.keras.metrics import Precision, Recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5tiiE9UPvCA"
      },
      "source": [
        "## 6.2 Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeK7LwaKPvCB"
      },
      "outputs": [],
      "source": [
        "# Get a batch of test data\n",
        "test_input, test_val, y_true = test_data.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "OjVktybzPvCB"
      },
      "outputs": [],
      "source": [
        "y_hat = siamese_model.predict([test_input, test_val])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "8MdD24EbPvCB"
      },
      "outputs": [],
      "source": [
        "# Post processing the results \n",
        "[1 if prediction > 0.5 else 0 for prediction in y_hat ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "wvCg8nUfPvCB"
      },
      "outputs": [],
      "source": [
        "y_true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOZ8DlJbPvCB"
      },
      "source": [
        "## 6.3 Calculate Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKvVTbvZPvCC"
      },
      "outputs": [],
      "source": [
        "# Creating a metric object \n",
        "m = Recall()\n",
        "\n",
        "# Calculating the recall value \n",
        "m.update_state(y_true, y_hat)\n",
        "\n",
        "# Return Recall Result\n",
        "m.result().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdU6CPSqPvCC"
      },
      "outputs": [],
      "source": [
        "# Creating a metric object \n",
        "m = Precision()\n",
        "\n",
        "# Calculating the recall value \n",
        "m.update_state(y_true, y_hat)\n",
        "\n",
        "# Return Recall Result\n",
        "m.result().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jlw5SCdTPvCC"
      },
      "outputs": [],
      "source": [
        "r = Recall()\n",
        "p = Precision()\n",
        "\n",
        "for test_input, test_val, y_true in test_data.as_numpy_iterator():\n",
        "    yhat = siamese_model.predict([test_input, test_val])\n",
        "    r.update_state(y_true, yhat)\n",
        "    p.update_state(y_true,yhat) \n",
        "\n",
        "print(r.result().numpy(), p.result().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZiOuLMvPvCC"
      },
      "source": [
        "## 6.4 Viz Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dwu4fIHXPvCD"
      },
      "outputs": [],
      "source": [
        "# Set plot size \n",
        "plt.figure(figsize=(10,8))\n",
        "\n",
        "# Set first subplot\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(test_input[0])\n",
        "\n",
        "# Set second subplot\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(test_val[0])\n",
        "\n",
        "# Renders cleanly\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS-rEme7PvCD"
      },
      "source": [
        "# 7. Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWEZUp8hPvCD"
      },
      "outputs": [],
      "source": [
        "# Save weights\n",
        "siamese_model.save('siamesemodelv2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCNSxsJ6PvCD"
      },
      "outputs": [],
      "source": [
        "L1Dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-HY7TYZPvCE"
      },
      "outputs": [],
      "source": [
        "# Reload model \n",
        "siamese_model = tf.keras.models.load_model('siamesemodelv2.h5', \n",
        "                                   custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8K6UixXVPvCE"
      },
      "outputs": [],
      "source": [
        "# Make predictions with reloaded model\n",
        "siamese_model.predict([test_input, test_val])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yt7rqnJqPvCE"
      },
      "outputs": [],
      "source": [
        "# View model summary\n",
        "siamese_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3I0xw-VPvCE"
      },
      "source": [
        "# 8. Real Time Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12OAS6MOPvCE"
      },
      "source": [
        "## 8.1 Verification Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okZgRpDGPvCF"
      },
      "outputs": [],
      "source": [
        "application_data/verification_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsC-rtxvPvCF"
      },
      "outputs": [],
      "source": [
        "os.listdir(os.path.join('application_data', 'verification_images'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frkz1Re1PvCF"
      },
      "outputs": [],
      "source": [
        "os.path.join('application_data', 'input_image', 'input_image.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzS5XO-yPvCF"
      },
      "outputs": [],
      "source": [
        "for image in os.listdir(os.path.join('application_data', 'verification_images')):\n",
        "    validation_img = os.path.join('application_data', 'verification_images', image)\n",
        "    print(validation_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QF6QrCtNPvCF"
      },
      "outputs": [],
      "source": [
        "def verify(model, detection_threshold, verification_threshold):\n",
        "    # Build results array\n",
        "    results = []\n",
        "    for image in os.listdir(os.path.join('application_data', 'verification_images')):\n",
        "        input_img = preprocess(os.path.join('application_data', 'input_image', 'input_image.jpg'))\n",
        "        validation_img = preprocess(os.path.join('application_data', 'verification_images', image))\n",
        "        \n",
        "        # Make Predictions \n",
        "        result = model.predict(list(np.expand_dims([input_img, validation_img], axis=1)))\n",
        "        results.append(result)\n",
        "    \n",
        "    # Detection Threshold: Metric above which a prediciton is considered positive \n",
        "    detection = np.sum(np.array(results) > detection_threshold)\n",
        "    \n",
        "    # Verification Threshold: Proportion of positive predictions / total positive samples \n",
        "    verification = detection / len(os.listdir(os.path.join('application_data', 'verification_images'))) \n",
        "    verified = verification > verification_threshold\n",
        "    \n",
        "    return results, verified"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqAZwoeLPvCF"
      },
      "source": [
        "## 8.2 OpenCV Real Time Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4S6DJmv_PvCG"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(4)\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    frame = frame[120:120+250,200:200+250, :]\n",
        "    \n",
        "    cv2.imshow('Verification', frame)\n",
        "    \n",
        "    # Verification trigger\n",
        "    if cv2.waitKey(10) & 0xFF == ord('v'):\n",
        "        # Save input image to application_data/input_image folder \n",
        "#         hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "#         h, s, v = cv2.split(hsv)\n",
        "\n",
        "#         lim = 255 - 10\n",
        "#         v[v > lim] = 255\n",
        "#         v[v <= lim] -= 10\n",
        "        \n",
        "#         final_hsv = cv2.merge((h, s, v))\n",
        "#         img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "        cv2.imwrite(os.path.join('application_data', 'input_image', 'input_image.jpg'), frame)\n",
        "        # Run verification\n",
        "        results, verified = verify(siamese_model, 0.5, 0.5)\n",
        "        print(verified)\n",
        "    \n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6N7RwR21PvCG"
      },
      "outputs": [],
      "source": [
        "np.sum(np.squeeze(results) > 0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmgVlXZbPvCG"
      },
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48Ac9lpAPvCG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "faceid",
      "language": "python",
      "name": "faceid"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-DDf4j9XPvBo"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}